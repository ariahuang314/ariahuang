# ESG Metrics Extraction and Standardization

## Overview

This branch provides a suite of Python scripts designed to automate the extraction of Environmental, Social and Governance (ESG) metrics from PDF reports. The workflow includes data extraction, cleaning, and similarity matching to standardize the extracted metrics.

## Repository Structure

### 1. dictionary
- `dictionary_new.xlsx` is a foundational input file that drives the categorization and keyword mapping logic of the script. It ensures that metrics and their attributes are correctly read, categorized, and exported for downstream processes.
  
- `qualitative_metrics_keywords.json`: An output file derived from metrics in `dictionary_new.xlsx` where the "Indicators category" is labeled as "Exposure". It provides a mapping between qualitative metrics and their associated keywords.

- `quantity_metrics_keywords.json`: An output file generated by excluding qualitative metrics from the complete metrics-to-keywords mapping (`metrics_keywords`). This file stores the relationships between non-qualitative metrics and their corresponding keywords.

### 2. scr ([detailed explanation](https://github.com/ariahuang314/groupproject/wiki/3-Automated-ESG-Metric-Extraction-and-Processing-Workflow))
- `main.py`: Running this file directly executes the entire data extraction and processing workflow in the `scr` folder. It collaborates with multiple modules to complete the tasks: loading the required files (`load_file`), analyzing data using the language model (`load_llm_model`) and supplement model (`load_supplement_model`), processing metric data with the merging and similarity calculation modules (`merge_metric and calculate_simliarity`), saving the results to the database (`save_db`) and scoring the data (`scoring_metric`).
  
- `pdf_to_txt.py`: We convert the ESG reports to texts by using regularization and provide a pipeline to convert PDF files into clean, structured text files, particularly useful for processing documents for further text analysis.
  
- `divide_quantity_qualitative.py`: From the dictionary created, we divide metrics into qualitative and quantitative categories and save them to `.json` files.
  
- `llm_model.py`: We define a pipeline for extracting ESG-related metrics from semi-structured text using OpenAI's language model, specifically configured for environmental, social, and governance data. It provides utilities to retrieve ESG indicators, values, units, and confidence scores from raw text and then saves the results in CSV format.
  
- `supplement_model.py`: We load a sentiment analysis model to process qualitative metrics based on a JSON file of metric keywords. The function searches for keyword matches within the text file and splits matched sentences into shorter sub-sentences for analysis. Using it, we evaluate each sub-sentence to obtian sentiment and confidence score. For each detected metric, we assign a value of 1, store it in a new DataFrame alongside its confidence score and drop duplicates.
  
- `merge_similarity.py`: In this code file, we merge the quantitative and qualitative metrics from separate files and process these metrics with a BERT model to identify semantic similarities to the target labels. The outcomes are saved based on the similarity thresholds.
  
- `save_to_db.py`: In this file, we upload the processed data to the MySQL database. We align column names with the database schema and uses `SQLAlchemy` to insert the data into a specified table, enabling efficient data management and querying.

- `scoring_code.py`: We calculate the ESG scores and ratings for target companies. This file retrieves the latest company data from a database, compares it with industry averages and applies scoring rules to generate individual scores for Environment (E), Social (S), Governance (G) and an overall score. The results, including detailed metrics and ratings, are then stored back in the database for further analysis. 

### 3. upload
- Upload ESG reports to this folder and the `pdf_to_txt.py` file will read their contents, converting the PDFs into text files stored in the `txt` folder for subsequent analysis.

### 4. txt
- The TXT files converted by `pdf_to_txt.py` will be saved here and later read and processed by `llm_model.py`.

### 5. output_metric
- `Quantity_metrics.csv`: Stores data extracted using quantitative metrics, which includes numerical information, such as amounts or ratios, for further processing and merging.

- `Qualitative_metrics_filter.csv`: Generated by matching qualitative metrics and their associated keywords from `qualitative_metrics_keywords.json`, performing sentiment analysis and filtering the results based on confidence and relevance. It contains filtered qualitative metrics data.This file includes metrics matched with target labels, facilitating subsequent analysis and standardization.

- `metrics.csv`: Holds the combined data of quantitative and qualitative metrics. This output file integrates all metrics and serves as the data source for similarity calculations.

- `metrics_filter.csv`: Contains high-quality metrics filtered from the merged data. After BERT embedding and similarity calculations, the data is refined and cleaned for further usage and analysis.

---------------------------------------------------------------------
